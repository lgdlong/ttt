"""
LLM Manager - Factory cho c√°c LLM providers
"""

import os
from typing import Optional, Dict
from dotenv import load_dotenv
from llm import GeminiProvider, OpenAIProvider
from base import BaseLLMProvider

# Load environment variables
load_dotenv()


class LLMManager:
    """
    Qu·∫£n l√Ω v√† t·∫°o c√°c LLM providers
    Factory pattern v·ªõi support cho nhi·ªÅu providers
    """
    
    def __init__(self):
        self.providers: Dict[str, BaseLLMProvider] = {}
        self._load_providers()
    
    def _load_providers(self):
        """Load providers t·ª´ environment variables"""
        
        # Load Gemini
        gemini_keys = os.getenv("GEMINI_API_KEYS", "")
        if gemini_keys:
            keys = [k.strip() for k in gemini_keys.split(",") if k.strip()]
            if keys:
                model = os.getenv("GEMINI_MODEL", "gemini-2.0-flash-exp")
                self.providers["gemini"] = GeminiProvider(keys, model)
                print(f"‚úÖ Loaded Gemini provider with {len(keys)} key(s), model: {model}")
        
        # Load OpenAI
        openai_keys = os.getenv("OPENAI_API_KEYS", "")
        if openai_keys:
            keys = [k.strip() for k in openai_keys.split(",") if k.strip()]
            if keys:
                model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
                base_url = os.getenv("OPENAI_BASE_URL")  # Custom base URL for third-party services
                self.providers["openai"] = OpenAIProvider(keys, model, base_url)
                
                if base_url:
                    print(f"‚úÖ Loaded OpenAI provider with {len(keys)} key(s), model: {model}, base_url: {base_url}")
                else:
                    print(f"‚úÖ Loaded OpenAI provider with {len(keys)} key(s), model: {model}")
        
        if not self.providers:
            raise ValueError(
                "Kh√¥ng t√¨m th·∫•y API key cho b·∫•t k·ª≥ provider n√†o!\n"
                "H√£y set √≠t nh·∫•t m·ªôt trong c√°c bi·∫øn m√¥i tr∆∞·ªùng:\n"
                "  - GEMINI_API_KEYS=key1,key2\n"
                "  - OPENAI_API_KEYS=key1,key2"
            )
        
        # Set default provider
        default = os.getenv("DEFAULT_AI_PROVIDER", "gemini").lower()
        if default not in self.providers:
            default = list(self.providers.keys())[0]
        
        self.default_provider = default
        print(f"üéØ Default provider: {self.default_provider}")
    
    def get_provider(self, provider: Optional[str] = None) -> BaseLLMProvider:
        """
        L·∫•y provider instance
        
        Args:
            provider: T√™n provider ("gemini", "openai"). N·∫øu None, d√πng default
            
        Returns:
            Provider instance
        """
        provider_name = provider or self.default_provider
        
        if provider_name not in self.providers:
            available = ", ".join(self.providers.keys())
            raise ValueError(
                f"Provider '{provider_name}' kh√¥ng c√≥ s·∫µn.\n"
                f"Available: {available}"
            )
        
        return self.providers[provider_name]
    
    def get_available_providers(self) -> list[str]:
        """L·∫•y danh s√°ch providers c√≥ s·∫µn"""
        return list(self.providers.keys())
    
    async def close_all(self):
        """ƒê√≥ng t·∫•t c·∫£ providers"""
        for provider in self.providers.values():
            await provider.close()


# Singleton instance
llm_manager = LLMManager()
