# Agents - Multi-Provider AI Automation Framework

## ğŸ¯ Tá»•ng quan

Framework automation vá»›i há»— trá»£ **nhiá»u AI providers** sá»­ dá»¥ng **official SDKs**:
- âœ… Google Gemini (via `google-generativeai`)
- âœ… OpenAI (via `openai`)
- ğŸ”§ Dá»… dÃ ng má»Ÿ rá»™ng thÃªm provider khÃ¡c

## ğŸ“ Kiáº¿n trÃºc má»›i

```
agents/
â”œâ”€â”€ base/                    # Base classes & interfaces
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ provider.py         # BaseLLMProvider interface
â”‚
â”œâ”€â”€ llm/                     # LLM providers implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ gemini.py           # Google Gemini provider (official SDK)
â”‚   â”œâ”€â”€ openai.py           # OpenAI provider (official SDK)
â”‚   â””â”€â”€ manager.py          # LLM Manager (factory)
â”‚
â”œâ”€â”€ utils/                   # Utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ optimizer.py        # Context optimizer, JSON parser
â”‚   â”œâ”€â”€ logger.py           # Structured logging
â”‚   â””â”€â”€ update_json_start_time.py  # Fix tool for missing start_time fields
â”‚
â”œâ”€â”€ workflows/               # Automation workflows
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ transcript_to_json.py  # Transcript to JSON workflow
â”‚
â”œâ”€â”€ prompts/                 # Prompt templates
â”‚   â””â”€â”€ transcript_to_json_instruction.md
â”‚
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ test_providers.py        # Test suite
â”œâ”€â”€ .env                     # Configuration (gitignored)
â”œâ”€â”€ .env.example             # Configuration template
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md               # This file
```

## ğŸ”„ Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   main.py    â”‚  â† Entry point
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  workflows/               â”‚
â”‚  transcript_to_json.py    â”‚  â† Workflow logic
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  llm/manager.py           â”‚  â† Factory & provider manager
â”‚  (LLMManager)             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  llm/                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚gemini.py â”‚     â”‚openai.py â”‚ ...    â”‚  â† Provider implementations
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚     (using official SDKs)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  base/provider.py         â”‚  â† Base interface
â”‚  (BaseLLMProvider)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Thiáº¿t láº­p

### 1. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

**Dependencies:**
- `google-genai` - Google Gemini official SDK (latest)
- `openai` - OpenAI official SDK  
- `python-dotenv` - Load .env files

### 2. Cáº¥u hÃ¬nh API Keys

Sao chÃ©p file máº«u:
```bash
cp .env.example .env
```

Chá»‰nh sá»­a `.env`:
```bash
# Chá»n provider máº·c Ä‘á»‹nh
DEFAULT_AI_PROVIDER=gemini

# Gemini configuration
GEMINI_API_KEYS=key1,key2,key3
GEMINI_MODEL=gemini-2.0-flash-exp

# OpenAI configuration
OPENAI_API_KEYS=sk-proj-key1,sk-proj-key2
OPENAI_MODEL=gpt-4o-mini

# Custom Base URL cho dá»‹ch vá»¥ OpenAI bÃªn thá»© 3 (optional)
# VÃ­ dá»¥: https://v98store.com/v1
# Náº¿u khÃ´ng set, dÃ¹ng API gá»‘c cá»§a OpenAI
OPENAI_BASE_URL=
```

**LÆ°u Ã½:** Náº¿u báº¡n sá»­ dá»¥ng dá»‹ch vá»¥ OpenAI bÃªn thá»© 3, hÃ£y set `OPENAI_BASE_URL`. VÃ­ dá»¥:

```bash
OPENAI_BASE_URL=https://v98store.com/v1
```

API call format sáº½ lÃ :
```
POST https://v98store.com/v1/chat/completions
Authorization: Bearer YOUR_API_KEY
```

### 3. Cháº¡y workflow

```bash
# DÃ¹ng default provider
python main.py

# Chá»‰ Ä‘á»‹nh provider cá»¥ thá»ƒ
python main.py gemini
python main.py openai
```

## ğŸ›  Utilities

### Cáº­p nháº­t start_time cho JSON output

Trong trÆ°á»ng há»£p cÃ¡c tá»‡p JSON output thiáº¿u trÆ°á»ng `start_time` (cáº§n thiáº¿t cho quÃ¡ trÃ¬nh import vÃ o database), báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ´ng cá»¥ sau Ä‘á»ƒ bá»• sung giÃ¡ trá»‹ máº·c Ä‘á»‹nh (`0`):

```bash
python agents/utils/update_json_start_time.py
```

CÃ´ng cá»¥ nÃ y sáº½ quÃ©t thÆ° má»¥c `agents/resources/transcript_to_json/output` vÃ  cáº­p nháº­t táº¥t cáº£ cÃ¡c tá»‡p JSON cÃ³ cáº¥u trÃºc `transcript`.

## 4. Cháº¡y tests

```bash
python test_providers.py
```

## ğŸ’¡ Sá»­ dá»¥ng

### Cháº¡y workflow cÃ³ sáºµn

```python
import asyncio
from workflows import run_transcript_to_json

# Run vá»›i default provider
asyncio.run(run_transcript_to_json())

# Run vá»›i provider cá»¥ thá»ƒ
asyncio.run(run_transcript_to_json(provider="openai"))
```

### Sá»­ dá»¥ng LLM Manager trá»±c tiáº¿p

```python
from llm.manager import llm_manager

# Get default provider
provider = llm_manager.get_provider()

# Generate text
result = await provider.generate(
    prompt="Your prompt",
    system_instruction="System instruction"
)

# Get specific provider
gemini = llm_manager.get_provider("gemini")
openai = llm_manager.get_provider("openai")
```

### Táº¡o workflow má»›i

```python
# workflows/your_workflow.py
import asyncio
from llm.manager import llm_manager
from utils import ContextOptimizer

async def your_workflow():
    # Get LLM provider
    llm = llm_manager.get_provider()
    
    # Your logic here
    result = await llm.generate(
        prompt="Your prompt",
        system_instruction="Your instruction"
    )
    
    # Process result
    data = ContextOptimizer.parse_json_safely(result)
    
    return data

if __name__ == "__main__":
    asyncio.run(your_workflow())
```

## Cáº¥u hÃ¬nh cÃ³ thá»ƒ tÃ¹y chá»‰nh

### config_manager.py
- `DEFAULT_PROVIDER` - Provider máº·c Ä‘á»‹nh ("gemini", "openai")
- `DEFAULT_GEMINI_MODEL` - Model Gemini máº·c Ä‘á»‹nh
- `DEFAULT_OPENAI_MODEL` - Model OpenAI máº·c Ä‘á»‹nh
- `MAX_RETRIES` - Sá»‘ láº§n retry tá»‘i Ä‘a
- `RETRY_BASE_MS` - Thá»i gian delay cÆ¡ báº£n (ms)

### llm_providers.py
- `CONNECTOR_LIMIT` - Sá»‘ káº¿t ná»‘i TCP tá»‘i Ä‘a
- `KEEPALIVE_TIMEOUT` - Timeout keepalive (giÃ¢y)
- `TEMPERATURE` - Temperature cho AI (0.0-1.0)
- `MAX_OUTPUT_TOKENS` - Sá»‘ token tá»‘i Ä‘a output
- `JITTER_MAX_MS` - Random jitter tá»‘i Ä‘a (ms)

### main.py
- `INPUT_DIR` - ThÆ° má»¥c chá»©a file input
- `MAX_CONCURRENT_WORKERS` - Sá»‘ worker cháº¡y Ä‘á»“ng thá»i
- `INPUT_FILE_EXT` - Extension file input
- `OUTPUT_FILE_EXT` - Extension file output
- `ENCODING` - Encoding file

### optimization_utils.py
- `TOKEN_ESTIMATE_DIVISOR` - Æ¯á»›c lÆ°á»£ng token
- `MAX_CONTENT_CHARS` - Äá»™ dÃ i content tá»‘i Ä‘a

## Workflow

1. **Input**: Äá»c file `.f.txt` tá»« `INPUT_DIR`
2. **Optimize**: Cáº¯t bá»›t ná»™i dung náº¿u quÃ¡ dÃ i
3. **Process**: Gá»i AI API (Gemini/OpenAI) Ä‘á»ƒ phÃ¢n tÃ­ch transcript
4. **Validate**: Kiá»ƒm tra JSON output há»£p lá»‡
5. **Output**: LÆ°u káº¿t quáº£ vÃ o file `.json`

## Features

### âœ… Multi-Provider Support
- Há»— trá»£ nhiá»u AI providers (Gemini, OpenAI)
- Dá»… dÃ ng má»Ÿ rá»™ng thÃªm provider má»›i
- Chuyá»ƒn Ä‘á»•i provider runtime

### âœ… Intelligent Retry Logic
- Exponential backoff vá»›i jitter
- Round-robin API key rotation
- Tá»± Ä‘á»™ng chuyá»ƒn key khi rate limit

### âœ… Error Handling
- Network error â†’ Retry vá»›i delay
- Rate limit â†’ Chuyá»ƒn key + exponential backoff
- Invalid JSON â†’ LÆ°u raw output Ä‘á»ƒ debug

## Troubleshooting

### Lá»—i "KhÃ´ng tÃ¬m tháº¥y API key"
```bash
# Kiá»ƒm tra file .env cÃ³ tá»“n táº¡i khÃ´ng
ls .env

# Kiá»ƒm tra ná»™i dung
cat .env

# Äáº£m báº£o cÃ³ Ã­t nháº¥t má»™t provider Ä‘Æ°á»£c cáº¥u hÃ¬nh
```

### Lá»—i "Provider khÃ´ng Ä‘Æ°á»£c implement"
```bash
# Kiá»ƒm tra tÃªn provider trong .env
# Pháº£i lÃ : "gemini" hoáº·c "openai" (lowercase)
DEFAULT_AI_PROVIDER=gemini
```

### Rate limit quÃ¡ nhanh
```bash
# Giáº£m MAX_CONCURRENT_WORKERS trong main.py
MAX_CONCURRENT_WORKERS = 2

# Hoáº·c thÃªm nhiá»u API key hÆ¡n
GEMINI_API_KEYS=key1,key2,key3,key4,key5
```
